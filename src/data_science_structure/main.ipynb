{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use Software Engineering to improve Data Science Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Data Science has to stop producing Spaghetti Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a common Data Scientist, I know the pain. Usually, what we do is pretty straight forward processwise, but somehow this almost always end up with a code that has become so complex, it's hard to keep track. Moreover, most Data Scientist do not really care about Software Engineering and use functions and classes all over the place, without any proper thinking about it first. Admittedly, I also did code like that.\n",
    "\n",
    "For some time now I wanted to change this. After reading some books and articles about Software Engineering and watching a ton of YouTube tutorials on it (thanks so much internet!) I came up with a few ideas how every Data Scientist can and should improve her code. Let's start with the basic design pattern I found helpful for each of my Data Science projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Information Expert Principle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This principle is pretty straightforward, but when applying it from the start of your project it will help you a lot writing cleaner and more beautiful code. It means that the design of your software (which, in the end, is what we are writing) should follow the data pipeline. What does this mean in action? Let me give you a brief example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import *\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class BaseData():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def load_data(self, data_path:str):\n",
    "        self.df_train = pd.read_csv(f'{data_path}/ItalyPowerDemand_TRAIN.txt', header=None,delim_whitespace=True)\n",
    "        self.df_test = pd.read_csv(f'{data_path}/ItalyPowerDemand_TEST.txt', header=None, delim_whitespace=True)\n",
    "\n",
    "    def make_fake_cat_vars(self):\n",
    "        \"\"\"Takes dataframe as input and transforms data\"\"\"\n",
    "        # let's add a categorical variable\n",
    "        countries = ['Germany', 'US']\n",
    "        household_income = ['low', 'high']\n",
    "        self.df_train[\"country\"] = np.random.choice(countries, len(self.df_train))\n",
    "        self.df_test[\"country\"] = np.random.choice(countries, len(self.df_test))\n",
    "        self.df_train[\"household_income\"] = np.random.choice(household_income, len(self.df_train))\n",
    "        self.df_test[\"household_income\"] = np.random.choice(household_income, len(self.df_test))\n",
    "\n",
    "    def transform_data(self):\n",
    "        self.x_train = self.df_train.iloc[:, 1:-2].values.reshape(-1, 1, 24)\n",
    "        self.x_test = self.df_test.iloc[:, 1:-2].values.reshape(-1, 1, 24)\n",
    "\n",
    "        self.y_train = self.df_train.iloc[:, 0].values-1\n",
    "        self.y_test = self.df_test.iloc[:, 0].values-1\n",
    "\n",
    "        self.emb_vars_train = self.df_train.iloc[:, -2:].values\n",
    "        self.emb_vars_test = self.df_test.iloc[:, -2:].values\n",
    "\n",
    "    def categorize_variables(self):\n",
    "        self.emb_vars_train, self.emb_vars_test, self.dict_embs, self.dict_inv_embs = \\\n",
    "            cat_transform(self.emb_vars_train, self.emb_vars_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data = BaseData()\n",
    "base_data.load_data('data')\n",
    "base_data.make_fake_cat_vars()\n",
    "base_data.transform_data()\n",
    "base_data.categorize_variables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>country</th>\n",
       "      <th>household_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.710518</td>\n",
       "      <td>-1.183320</td>\n",
       "      <td>-1.372442</td>\n",
       "      <td>-1.593083</td>\n",
       "      <td>-1.467002</td>\n",
       "      <td>-1.372442</td>\n",
       "      <td>-1.088760</td>\n",
       "      <td>0.045967</td>\n",
       "      <td>0.928532</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206195</td>\n",
       "      <td>0.613330</td>\n",
       "      <td>1.369815</td>\n",
       "      <td>1.464375</td>\n",
       "      <td>1.054613</td>\n",
       "      <td>0.581810</td>\n",
       "      <td>0.172048</td>\n",
       "      <td>-0.269235</td>\n",
       "      <td>Germany</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.993009</td>\n",
       "      <td>-1.426786</td>\n",
       "      <td>-1.579884</td>\n",
       "      <td>-1.605401</td>\n",
       "      <td>-1.630917</td>\n",
       "      <td>-1.375754</td>\n",
       "      <td>-1.018526</td>\n",
       "      <td>-0.355102</td>\n",
       "      <td>0.716583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614518</td>\n",
       "      <td>0.308322</td>\n",
       "      <td>0.257289</td>\n",
       "      <td>1.099327</td>\n",
       "      <td>1.048295</td>\n",
       "      <td>0.691066</td>\n",
       "      <td>-0.048906</td>\n",
       "      <td>-0.380618</td>\n",
       "      <td>Germany</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.319067</td>\n",
       "      <td>0.569774</td>\n",
       "      <td>0.195128</td>\n",
       "      <td>-0.085856</td>\n",
       "      <td>-0.179518</td>\n",
       "      <td>-0.273180</td>\n",
       "      <td>-0.085856</td>\n",
       "      <td>-1.397118</td>\n",
       "      <td>-1.116134</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.741487</td>\n",
       "      <td>-0.741487</td>\n",
       "      <td>-1.116134</td>\n",
       "      <td>-0.460503</td>\n",
       "      <td>0.476113</td>\n",
       "      <td>2.349344</td>\n",
       "      <td>2.255682</td>\n",
       "      <td>1.600052</td>\n",
       "      <td>Germany</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.812444</td>\n",
       "      <td>-1.157553</td>\n",
       "      <td>-1.416385</td>\n",
       "      <td>-1.531421</td>\n",
       "      <td>-1.502662</td>\n",
       "      <td>-1.416385</td>\n",
       "      <td>-1.646458</td>\n",
       "      <td>-0.467335</td>\n",
       "      <td>0.654269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884342</td>\n",
       "      <td>0.683028</td>\n",
       "      <td>0.625510</td>\n",
       "      <td>0.424197</td>\n",
       "      <td>-0.007190</td>\n",
       "      <td>-0.035949</td>\n",
       "      <td>0.107847</td>\n",
       "      <td>-0.266022</td>\n",
       "      <td>Germany</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.972840</td>\n",
       "      <td>-1.390518</td>\n",
       "      <td>-1.536705</td>\n",
       "      <td>-1.620240</td>\n",
       "      <td>-1.620240</td>\n",
       "      <td>-1.453169</td>\n",
       "      <td>-0.993724</td>\n",
       "      <td>0.050469</td>\n",
       "      <td>0.635218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614334</td>\n",
       "      <td>1.303502</td>\n",
       "      <td>1.240850</td>\n",
       "      <td>1.073779</td>\n",
       "      <td>0.551682</td>\n",
       "      <td>0.426379</td>\n",
       "      <td>-0.179253</td>\n",
       "      <td>-0.638698</td>\n",
       "      <td>Germany</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6         7  \\\n",
       "0  1.0 -0.710518 -1.183320 -1.372442 -1.593083 -1.467002 -1.372442 -1.088760   \n",
       "1  1.0 -0.993009 -1.426786 -1.579884 -1.605401 -1.630917 -1.375754 -1.018526   \n",
       "2  2.0  1.319067  0.569774  0.195128 -0.085856 -0.179518 -0.273180 -0.085856   \n",
       "3  2.0 -0.812444 -1.157553 -1.416385 -1.531421 -1.502662 -1.416385 -1.646458   \n",
       "4  1.0 -0.972840 -1.390518 -1.536705 -1.620240 -1.620240 -1.453169 -0.993724   \n",
       "\n",
       "          8         9  ...        17        18        19        20        21  \\\n",
       "0  0.045967  0.928532  ... -0.206195  0.613330  1.369815  1.464375  1.054613   \n",
       "1 -0.355102  0.716583  ...  0.614518  0.308322  0.257289  1.099327  1.048295   \n",
       "2 -1.397118 -1.116134  ... -0.741487 -0.741487 -1.116134 -0.460503  0.476113   \n",
       "3 -0.467335  0.654269  ...  0.884342  0.683028  0.625510  0.424197 -0.007190   \n",
       "4  0.050469  0.635218  ...  0.614334  1.303502  1.240850  1.073779  0.551682   \n",
       "\n",
       "         22        23        24  country  household_income  \n",
       "0  0.581810  0.172048 -0.269235  Germany               low  \n",
       "1  0.691066 -0.048906 -0.380618  Germany              high  \n",
       "2  2.349344  2.255682  1.600052  Germany               low  \n",
       "3 -0.035949  0.107847 -0.266022  Germany               low  \n",
       "4  0.426379 -0.179253 -0.638698  Germany               low  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_data.df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: 'US', 1: 'Germany'}, {0: 'low', 1: 'high'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_data.dict_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_data.emb_vars_train[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens here is that everything connected to the data is now stored in the BaseData class. Each and every function within this class needs the data where it is and gets the data directly, so there is no jumping to other objects or methods to make this happen. So my first take away: keep your data together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will use this data to pass it on to the next point within our pipeline. Just to keep you informed, what I do here is actually a refactoring of an earlier project of mine, where I will use a convolutional neural network in PyTorch to classify a timeseries. So in order to use PyTorches power, the data needs to be in so called Dataloaders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "from dataloaders import *\n",
    "\n",
    "device = DEVICE\n",
    "datasets = create_datasets(base_data.x_train, base_data.emb_vars_train, base_data.y_train,\n",
    "             base_data.x_test, base_data.emb_vars_test, base_data.y_test,\n",
    "             valid_pct=VAL_SIZE, seed=1234)\n",
    "data = DataBunch(*create_loaders(datasets, bs=1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to have a closer look at what this exactly does, just go inside the dataloaders.py file. Basically it splits the train_data into train and validation and then creates a PyTorch dataset from it. This then can be put into a dataloader. Now I could have used three different dataloaders, but again, I want to keep my data together, which is why I created a class called DataBunch (naming and idea stolen from fastai), where I have all of my data in one place. \n",
    "\n",
    "Furthermore, realize that I use one, and only one config file. I often see Code with different kind of constants aka configurations all over different files, which makes it extremely hard to later on debug the code or change settings. So please keep your constants in one place.\n",
    "\n",
    "Now let's have a closer how we can use a clever way of building models in a more flexible way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    \"\"\"Converts N-dimensional tensor into 'flat' one.\"\"\"\n",
    "\n",
    "    def __init__(self, keep_batch_dim=True):\n",
    "        super().__init__()\n",
    "        self.keep_batch_dim = keep_batch_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.keep_batch_dim:\n",
    "            return x.view(x.size(0), -1)\n",
    "        return x.view(-1)\n",
    "\n",
    "\n",
    "def conv1d(ni, nf, ks, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv1d(ni, nf, ks, stride=stride, padding=0), nn.BatchNorm1d(nf), nn.ReLU())\n",
    "\n",
    "\n",
    "def get_cnn_layers(input_shape, output_shapes:list, kernels:list, strides:list, drop=.5):\n",
    "    output_shapes = [input_shape] + output_shapes\n",
    "    return [\n",
    "        conv1d(output_shapes[i], output_shapes[i+1], kernels[i], strides[i])\n",
    "        for i in range(len(output_shapes)-1)\n",
    "    ] + [nn.MaxPool1d(2, stride=2), Flatten(), nn.Dropout(drop), nn.Linear(output_shapes[-1], 64), nn.ReLU(inplace=True),\n",
    "            nn.Dropout(drop), nn.Linear(64, 64), nn.ReLU(inplace=True)]\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    \"\"\"Model Baseclass.\"\"\"\n",
    "\n",
    "    def __init__(self, conv_layers, emb_dims, no):\n",
    "        super().__init__()\n",
    "\n",
    "        self.raw = conv_layers\n",
    "\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(x, y) for x, y in emb_dims])\n",
    "        no_of_embs = sum([y for x, y in emb_dims])\n",
    "        self.no_of_embs = no_of_embs\n",
    "        self.emb_dims = emb_dims\n",
    "\n",
    "        self.emb_out = nn.Sequential(\n",
    "            nn.Linear(no_of_embs, 64), nn.ReLU(inplace=True), nn.Linear(64, 64))\n",
    "\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(64 + 64, 64), nn.ReLU(inplace=True), nn.Linear(64, no))\n",
    "\n",
    "    def forward(self, t_raw, embeddings):  # this is where the data flows in later in the training\n",
    "        raw_out = self.raw(t_raw)\n",
    "        emb = [emb_layer(embeddings[:, i].long()) for i, emb_layer in enumerate(self.embeddings)]\n",
    "        # we want to concatenate convolutions and embeddings. Embeddings are of size (batch_size, no_of_embs),\n",
    "        # convolution of size (batch, 256, 1) so we need to add another dimension to the embeddings at dimension 2 (\n",
    "        # counting starts from 0)\n",
    "        emb_cat = torch.cat(emb, 1)\n",
    "        emb_cat = self.emb_out(emb_cat)\n",
    "        t_in = torch.cat([raw_out, emb_cat], dim=1)\n",
    "        out = self.out(t_in)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing to notice here is that I combined the basic structure of a Conv1d layer in one function. Every Conv1d layer should have a BatchNorm followed by a ReLU. You can adjust this just as you like. Then, in the next step I created a function which basically makes the Conv1d layer repetitive, given a list of arguments you provide. So based on that list of arguments, you can have 1, 2, 3, 4 or as many layer as you would like. This then in turn is then used in the Classifier class, which is our main model. The convolutional part, here called *self.raw* is then build given on what we specify how the architecture should look like. The rest of the model I kept rather inflexible, which you could if you want also change. But let's see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "raw_feat = base_data.x_train.shape[1]\n",
    "emb_dims = [(len(base_data.dict_embs[0]), EMB_DIMS), (len(base_data.dict_embs[1]), EMB_DIMS)]\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# model layers\n",
    "OUTPUT_SHAPES = [128]\n",
    "KERNELS = [23]\n",
    "STRIDES = [1]\n",
    "\n",
    "# create model\n",
    "model = Classifier(nn.Sequential(\n",
    "    *get_cnn_layers(raw_feat, OUTPUT_SHAPES, KERNELS, STRIDES)\n",
    "    ), emb_dims, NUM_CLASSES).to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything written in all caps is actually defined within the config file, but for seeing what's going on here I just put them into this code snippet. So if I wanted to add another layer, I could just go into my config file and change that, so that I have three layers with different kernels and strides. When doing experiments, you can just provide different settings in your config and then use them for your second model. Do not underestimate the idea of having parameters in one place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next big part is directly connected to the Information Expert principle. Let's start with the Learner, a simple idea based on that principle. When training the model, we need another class which keeps all the information needed, the Learner. And what information does the Learner need? The data, the model, the loss function and the optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self, model, opt, loss_func, data):\n",
    "        self.model,self.opt,self.loss_func,self.data = model,opt,loss_func,data\n",
    "\n",
    "learn = Learner(model, opt, loss_func, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to build the pipeline for our process, let's call it runner. We pass in the Learner, which is responsible for the data and modelling part. The runner itself only guides the data flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner():\n",
    "    def __init__(self, cbs=None, cb_funcs=None):\n",
    "        self.in_train = False\n",
    "        cbs = listify(cbs)\n",
    "        for cbf in listify(cb_funcs):\n",
    "            cb = cbf()\n",
    "            setattr(self, cb.name, cb)\n",
    "            cbs.append(cb)\n",
    "        self.stop,self.cbs = False,[TrainEvalCallback()]+cbs\n",
    "\n",
    "    @property\n",
    "    def opt(self):       return self.learn.opt\n",
    "    @property\n",
    "    def model(self):     return self.learn.model\n",
    "    @property\n",
    "    def loss_func(self): return self.learn.loss_func\n",
    "    @property\n",
    "    def data(self):      return self.learn.data\n",
    "\n",
    "    def one_batch(self, xb, emb, yb):\n",
    "        try:\n",
    "            self.xb,self.emb,self.yb = xb,emb,yb\n",
    "            self('begin_batch')\n",
    "            self.pred = self.model(self.xb,self.emb)\n",
    "            self('after_pred')\n",
    "            self.loss = self.loss_func(self.pred, self.yb)\n",
    "            self('after_loss')\n",
    "            if not self.in_train: return\n",
    "            self.loss.backward()\n",
    "            self('after_backward')\n",
    "            self.opt.step()\n",
    "            self('after_step')\n",
    "            self.opt.zero_grad()\n",
    "        except CancelBatchException: self('after_cancel_batch')\n",
    "        finally: self('after_batch')\n",
    "\n",
    "    def all_batches(self, dl):\n",
    "        self.iters = len(dl)\n",
    "        try:\n",
    "            for xb,emb,yb in dl: self.one_batch(xb, emb, yb)\n",
    "        except CancelEpochException: self('after_cancel_epoch')\n",
    "\n",
    "    def fit(self, epochs, learn):\n",
    "        self.epochs,self.learn,self.loss = epochs,learn,torch.tensor(0.)\n",
    "\n",
    "        try:\n",
    "            for cb in self.cbs: cb.set_runner(self)\n",
    "            self('begin_fit')\n",
    "            for epoch in range(epochs):\n",
    "                self.epoch = epoch\n",
    "                if not self('begin_epoch'): self.all_batches(self.data.train_dl)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    if not self('begin_validate'): self.all_batches(self.data.valid_dl)\n",
    "                self('after_epoch')\n",
    "\n",
    "        except CancelTrainException: self('after_cancel_train')\n",
    "        finally:\n",
    "            self('after_fit')\n",
    "            self.learn = None\n",
    "\n",
    "    def __call__(self, cb_name):\n",
    "        res = False\n",
    "        for cb in sorted(self.cbs, key=lambda x: x._order): res = cb(cb_name) or res\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last idea I want every Data Scientist to know about are Callbacks. Basically that means we're calling a different function and make use of their behaviour. To be able to clearly pinpoint where the Callback should be applied, I added things like *self('after_epoch')*. This then let's us easily create our own Callbacks which we can use exactly where we want to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Callback():\n",
    "    _order=0\n",
    "    def set_runner(self, run): self.run=run\n",
    "    def __getattr__(self, k): return getattr(self.run, k)\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        name = re.sub(r'Callback$', '', self.__class__.__name__)\n",
    "        return camel2snake(name or 'callback')\n",
    "\n",
    "    def __call__(self, cb_name):\n",
    "        f = getattr(self, cb_name, None)\n",
    "        if f and f(): return True\n",
    "        return False\n",
    "\n",
    "\n",
    "class Recorder(Callback):\n",
    "    def begin_fit(self):\n",
    "        self.lrs = [[] for _ in self.opt.param_groups]\n",
    "        self.losses = []\n",
    "\n",
    "    def after_batch(self):\n",
    "        if not self.in_train: return\n",
    "        for pg,lr in zip(self.opt.param_groups,self.lrs): lr.append(pg['lr'])\n",
    "        self.losses.append(self.loss.detach().cpu())\n",
    "\n",
    "    def plot_lr  (self, pgid=-1): plt.plot(self.lrs[pgid])\n",
    "    def plot_loss(self, skip_last=0): plt.plot(self.losses[:len(self.losses)-skip_last])\n",
    "\n",
    "    def plot(self, skip_last=0, pgid=-1):\n",
    "        losses = [o.item() for o in self.losses]\n",
    "        lrs    = self.lrs[pgid]\n",
    "        n = len(losses)-skip_last\n",
    "        plt.xscale('log')\n",
    "        plt.plot(lrs[:n], losses[:n])\n",
    "\n",
    "\n",
    "class LR_Find(Callback):\n",
    "    _order=1\n",
    "    def __init__(self, max_iter=100, min_lr=1e-6, max_lr=10):\n",
    "        self.max_iter,self.min_lr,self.max_lr = max_iter,min_lr,max_lr\n",
    "        self.best_loss = 1e9\n",
    "\n",
    "    def begin_batch(self):\n",
    "        if not self.in_train: return\n",
    "        pos = self.n_iter/self.max_iter\n",
    "        lr = self.min_lr * (self.max_lr/self.min_lr) ** pos\n",
    "        for pg in self.opt.param_groups: pg['lr'] = lr\n",
    "\n",
    "    def after_step(self):\n",
    "        if self.n_iter>=self.max_iter or self.loss>self.best_loss*10:\n",
    "            raise CancelTrainException()\n",
    "        if self.loss < self.best_loss: self.best_loss = self.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the base Callback class, each and every Callback we want to use inherits from it. Take the LR_Find Callback: This will be applied after a batch begins and after each step. These we have defined within our Runner class. Now we can use these Callbacks like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from callbacks import *\n",
    "\n",
    "run = Runner(cb_funcs=[LR_Find, Recorder])\n",
    "\n",
    "run.fit(100, learn)\n",
    "run.recorder.plot(skip_last=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add all sorts of Callbacks, we can also trigger a Tensorboard run as a Callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10\n",
      "train: [0.6974158377017615, tensor(0.3962)]\n",
      "valid: [0.6996233122689384, tensor(0.3571)]\n",
      "epoch: 20\n",
      "train: [0.2831651039843289, tensor(0.9434)]\n",
      "valid: [0.3708829198564802, tensor(1.)]\n",
      "epoch: 30\n",
      "train: [0.06155696904884195, tensor(0.9811)]\n",
      "valid: [0.00996389878647668, tensor(1.)]\n",
      "epoch: 40\n",
      "train: [0.013252086234542559, tensor(1.)]\n",
      "valid: [0.00019769343946661268, tensor(1.)]\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "model = Classifier(nn.Sequential(\n",
    "    *get_cnn_layers(raw_feat, OUTPUT_SHAPES, KERNELS, STRIDES)\n",
    "    ), emb_dims, NUM_CLASSES).to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=2e-3)\n",
    "\n",
    "cbfs = [Recorder, partial(AvgStatsCallback,adjusted_accu), partial(Tracker, RUN_PATH)]\n",
    "learn = Learner(model, opt, loss_func, data)\n",
    "run = Runner(cb_funcs=cbfs)\n",
    "run.fit(40, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This now has triggered a *run* for Tensorboard and saved it in this folder. We can now have a look at this by typing *tensorboard --logdir=runs* in the Terminal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/Tensorboard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it for now. I hope the idea of Information Expert Principle is now a bit more familiar, and I could give you some ideas of how to refactor your existing Data Science projects.\n",
    "\n",
    "Lasse"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f2a3cb876b6f7d7d51e77efe800c2c66d976d4bc9419edf69312132e0130ed55"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv_dl': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
